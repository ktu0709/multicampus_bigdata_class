{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7b91552d",
   "metadata": {},
   "source": [
    "<<KNN 분류 ,  KNN 회귀 모형 비교를 해서 예측 모델을 생성하자 >>\n",
    "\n",
    "분류 : neighbors.KNeighborsClassifier([...])  Classifier implementing the k-nearest neighbors vote.\n",
    "  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "  \n",
    "  weights='uniform (균일한 가중치' , 'distance( 거리에 대한 가중치  ' \n",
    "  \n",
    "  algorithm(ball_tree, kd_tree(2차원)과 leaf_size는 알고리즘에 따라 맵핑 \n",
    " \n",
    "  n_jobs (검색 작업수 ) = -1   : CPU 코어수가 설정된다.  \n",
    "         \n",
    "회귀 :neighbors.KNeighborsRegressor([n_neighbors, ...]) Regression based on k-nearest neighbors."
   ]
  },
  {
   "cell_type": "raw",
   "id": "67e9eb6d",
   "metadata": {},
   "source": [
    "KNN 분류 \n",
    "  \n",
    "  1) 새로운 값은 기존의 데이터를 기준으로 가까운 K개의 최근접 값을 기준으로 분류된다.  \n",
    "  \n",
    "  2) k = n_neighbors 는 동률의 문제 때문에 짝수는 되도록 피하는 것이 좋다. \n",
    "  \n",
    "  3) K가 1에 가까울 수록 과적합 , K가 클수록 과소적합이 되기 때문에 적절한 K가 필요하다.  \n",
    "  \n",
    "  4)  n_neighbors 인자에 학습시 고려할 이웃 데이터 개수를 지정한다.  \n",
    "  \n",
    "\n",
    "KNN 회귀 \n",
    "  \n",
    "  1) 새로운 값은 기존의 데이터를 기준으로 가까운 K개의 최근접 값을 기준으로 분류된다.  \n",
    "  \n",
    "  2) k는 동률의 문제 때문에 짝수는 되도록 피하는 것이 좋다. \n",
    "  \n",
    "  3) K가 1에 가까울 수록 과적합 , K가 클수록 과소적합이 되기 때문에 적절한 K가 필요하다. \n",
    "  \n",
    "  4) K개의 인접한 자료의 가중(평균)으로 예측 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbfc45",
   "metadata": {},
   "source": [
    "### Q1) KNeighborsClassifier를 이용한 정확도를 리턴받자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1dbe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7467532467532467"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 당뇨 발생 유무를 예측하기 위해 임신횟수, 혈당, 혈압을 사용할 경우 정확도를 확인 하자. \n",
    "# \"Pregnancies\", \"Glucose\", \"BloodPressure\"  ->X\n",
    "# \"Outcome\"   -> y \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics      import accuracy_score\n",
    "from sklearn.neighbors  import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드  \n",
    "df= pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "#데이터 분류 \n",
    "df_train, df_test = train_test_split(df, train_size =0.8 , random_state = 123)\n",
    "\n",
    "# 모델 생성 \n",
    "model  = KNeighborsClassifier() \n",
    "\n",
    "X  = df_train.loc[:, [\"Pregnancies\", \"Glucose\", \"BloodPressure\"]]\n",
    "y  = df_train[\"Outcome\"] \n",
    "\n",
    "#모델 실행  -> 학습데이터  \n",
    "model.fit(X,y)\n",
    "\n",
    "#예측   -> 테스트 데이터  \n",
    "pred = model.predict(df_test.loc[:,[\"Pregnancies\", \"Glucose\", \"BloodPressure\"]])\n",
    "pred[:5] #확인  \n",
    "\n",
    "#정확도   ->  예측값,  실제값이 값이 없어서 df_test 값으로  .. \n",
    "accuracy_score(y_pred = pred, y_true = df_test[\"Outcome\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915a1943",
   "metadata": {},
   "source": [
    "### Q2) 종속변수를 당뇨 발생 유무, 임신유무,혈당,혈압, 인슐린, 체질량 지수를 독립으로 하여 \n",
    "### 정확도를 확인 했을 때 K값과 정확도는?   학습 8: 평가 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f96c596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbors</th>\n",
       "      <th>accs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbors  accs\n",
       "0          3  0.71\n",
       "1          5  0.73\n",
       "2         10  0.78\n",
       "3         11  0.81\n",
       "4         20  0.76\n",
       "5         25  0.74\n",
       "6         30  0.77"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics      import accuracy_score\n",
    "from sklearn.neighbors  import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 데이터 로드  \n",
    "df= pd.read_csv('../../data/diabetes.csv')\n",
    "\n",
    "#2. 임신회수가 있고 임신의 유무가 없다.  컬럼 추가. \n",
    "df['is_preg'] = (df['Pregnancies'] > 0 ) +0\n",
    "df.head()\n",
    "\n",
    "#3.  데이터 분류 \n",
    "df_train, df_test = train_test_split(df, train_size =0.8 , random_state = 123)\n",
    "X_cols = ['is_preg', 'Glucose', 'BloodPressure', 'Insulin', 'BMI']\n",
    "\n",
    "neighbors =[3,5,10,11,20,25,30]\n",
    "accs =[] \n",
    "for k in neighbors:\n",
    "    model   =  KNeighborsClassifier(n_neighbors=k)   # 모델 생성  \n",
    "    model.fit(X=df_train.loc[:, X_cols] , y=df_train['Outcome'])  #모델 실행 \n",
    "    \n",
    "    pred = model.predict(df_test.loc[:, X_cols]) #예측값\n",
    "    acc_sub = accuracy_score(y_pred = pred, y_true= df_test['Outcome'] ) #정답 스코어 \n",
    "    accs= accs +[acc_sub]\n",
    "    \n",
    "#4.출력결과 \n",
    "df_score  = pd.DataFrame({'neighbors':neighbors,  'accs' :accs  })\n",
    "df_score['accs']= df_score['accs'].round(2)\n",
    "df_score\n",
    "\n",
    "# k=11, 정확도 0.81 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af84864",
   "metadata": {},
   "source": [
    "### Q3) 종속변수를 체질량 지수로 하고 , 임신유무,혈당,혈압, 인슐린 독립으로 하여 K, RMSE는 ?\n",
    "RMSE  -> mean_squared_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5bd5a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbors</th>\n",
       "      <th>rmses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>8.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>8.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>8.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>8.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>8.436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbors  rmses\n",
       "0          3  8.508\n",
       "1          5  8.706\n",
       "2         10  8.517\n",
       "3         11  8.467\n",
       "4         20  8.514\n",
       "5         25  8.449\n",
       "6         30  8.436"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics      import accuracy_score\n",
    "from sklearn.neighbors  import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. 데이터 로드  \n",
    "df= pd.read_csv('../../data/diabetes.csv')\n",
    "\n",
    "#2. 임신회수가 있고 임신의 유무가 없다.  컬럼 추가. \n",
    "df['is_preg'] = (df['Pregnancies'] > 0 ) +0\n",
    "df.head()\n",
    "\n",
    "#3.  데이터 분류 \n",
    "df_train, df_test = train_test_split(df, train_size =0.8 , random_state = 123)\n",
    "X_cols = ['is_preg', 'Glucose', 'BloodPressure', 'Insulin']\n",
    "\n",
    "neighbors =[3,5,10,11,20,25,30]\n",
    "rmses =[] \n",
    "for k in neighbors:\n",
    "    model   =  KNeighborsRegressor(n_neighbors=k)   # 모델 생성  \n",
    "    model.fit(X = df_train.loc[:, X_cols], y = df_train[\"BMI\"])  #모델 실행 \n",
    "    \n",
    "    pred = model.predict(df_test.loc[:, X_cols]) #예측값\n",
    "    rmse_sub = np.sqrt(mean_squared_error(y_pred = pred, y_true = df_test[\"BMI\"])) #정답 스코어\n",
    "    rmses= rmses +[rmse_sub]\n",
    "    \n",
    "#4.출력결과 \n",
    "df_score = pd.DataFrame({\"neighbors\": neighbors, \"rmses\": rmses})\n",
    "df_score[\"rmses\"] = df_score[\"rmses\"].round(3)\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6f2bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KNeighborsClassifier in module sklearn.neighbors._classification:\n",
      "\n",
      "class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n",
      " |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |  \n",
      " |  Classifier implementing the k-nearest neighbors vote.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, default=5\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : {'uniform', 'distance'} or callable, default='uniform'\n",
      " |      Weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, default=30\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : int, default=2\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : str or callable, default='minkowski'\n",
      " |      Metric to use for distance computation. Default is \"minkowski\", which\n",
      " |      results in the standard Euclidean distance when p = 2. See the\n",
      " |      documentation of `scipy.spatial.distance\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_ and\n",
      " |      the metrics listed in\n",
      " |      :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric\n",
      " |      values.\n",
      " |  \n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      " |      must be square during fit. X may be a :term:`sparse graph`, in which\n",
      " |      case only \"nonzero\" elements may be considered neighbors.\n",
      " |  \n",
      " |      If metric is a callable function, it takes two arrays representing 1D\n",
      " |      vectors as inputs and must return one value indicating the distance\n",
      " |      between those vectors. This works for Scipy's metrics, but is less\n",
      " |      efficient than passing the metric name as a string.\n",
      " |  \n",
      " |  metric_params : dict, default=None\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape (n_classes,)\n",
      " |      Class labels known to the classifier\n",
      " |  \n",
      " |  effective_metric_ : str or callble\n",
      " |      The distance metric used. It will be same as the `metric` parameter\n",
      " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      " |      'minkowski' and `p` parameter set to 2.\n",
      " |  \n",
      " |  effective_metric_params_ : dict\n",
      " |      Additional keyword arguments for the metric function. For most metrics\n",
      " |      will be same with `metric_params` parameter, but may also contain the\n",
      " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
      " |      'minkowski'.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_samples_fit_ : int\n",
      " |      Number of samples in the fitted data.\n",
      " |  \n",
      " |  outputs_2d_ : bool\n",
      " |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
      " |      otherwise True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
      " |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
      " |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
      " |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
      " |     but different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
      " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      " |  >>> neigh.fit(X, y)\n",
      " |  KNeighborsClassifier(...)\n",
      " |  >>> print(neigh.predict([[1.1]]))\n",
      " |  [0]\n",
      " |  >>> print(neigh.predict_proba([[0.9]]))\n",
      " |  [[0.666... 0.333...]]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsClassifier\n",
      " |      sklearn.neighbors._base.KNeighborsMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.neighbors._base.NeighborsBase\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the k-nearest neighbors classifier from the training dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : KNeighborsClassifier\n",
      " |          The fitted k-nearest neighbors classifier.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the class labels for the provided data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
      " |          Class labels for each data sample.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. Classes are ordered\n",
      " |          by lexicographic order.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Find the K-neighbors of a point.\n",
      " |      \n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors required for each sample. The default is the\n",
      " |          value passed to the constructor.\n",
      " |      \n",
      " |      return_distance : bool, default=True\n",
      " |          Whether or not to return the distances.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True.\n",
      " |      \n",
      " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NearestNeighbors\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples)\n",
      " |      NearestNeighbors(n_neighbors=1)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False)\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |          For ``metric='precomputed'`` the shape should be\n",
      " |          (n_queries, n_indexed). Otherwise the shape should be\n",
      " |          (n_queries, n_features).\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors for each sample. The default is the value\n",
      " |          passed to the constructor.\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are distances between points, type of distance\n",
      " |          depends on the selected metric parameter in\n",
      " |          NearestNeighbors class.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
      " |          `n_samples_fit` is the number of samples in the fitted data.\n",
      " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
      " |          The matrix is of CSR format.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
      " |          of Neighbors for points in X.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X)\n",
      " |      NearestNeighbors(n_neighbors=2)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(KNeighborsClassifier ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98bf89",
   "metadata": {},
   "source": [
    "### Q4) KNeighborsClassifier를 이용한 정확도를 리턴받자.\n",
    "## load_iris() 를 이용해서 분류 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e20840dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#1 . 데이터 로드\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y= iris.target\n",
    "\n",
    "#2. 데이터 확인  \n",
    "#print(\"데이터 수 = %d 특징량 = %d\" % (X.shape[0], X.shape[1])) #(150,4) \n",
    "pd.DataFrame(X, columns=iris.feature_names).head()\n",
    "\n",
    "# 데이터 표시(목적 변수)\n",
    "#print(\"데이터 수 = %d\" % (y.shape[0]))\n",
    "#print(y)\n",
    "\n",
    "#3. 데이터 분할\n",
    "X_train, X_test, y_train,y_test  = train_test_split(X,y, random_state = 0) \n",
    "#4.분류 모형 \n",
    "list_nn =[]\n",
    "list_score =[]\n",
    "for k in range(1,31) : # 1~30 \n",
    "    model = KNeighborsClassifier(n_neighbors =  k)\n",
    "    model.fit(X_train, y_train)  # 학습 데이터로  모델 실행     \n",
    "    y_pred  = model.predict(X_test)  # 테스트 데이터로 예측    \n",
    "    score  = model.score(X_test, y_test) # 테스트 데이터로 평가 -> R2값이 1이면 완벽예측 , 0이면 평균\n",
    "                                         # 분류 -> score  -> accuracy_score랑 같다.  \n",
    "    #print(\"[%d] score: {:.2f}\".format(score) % k)\n",
    "    \n",
    "    list_nn.append(k)\n",
    "    list_score.append(score)\n",
    "    \n",
    "#5. 시각화      \n",
    "plt.ylim(0.9,1.0)   ; \n",
    "plt.xlabel('n_neighbors');\n",
    "plt.ylabel('score');\n",
    "plt.plot(list_nn, list_score);\n",
    "#[평가 ]  k =1~30 /  k 1~23까지는 정밀도 97% 이지만  K=24 이상부터는 정밀도가 낮다 \n",
    "# * k값은  적은 수치도 문제가 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736dd360",
   "metadata": {},
   "source": [
    "### Q5) KNeighborsClassifier를 이용한 정확도를 리턴받자.\n",
    "## sklearn.datasets.load_breast_cancer() 를 이용해서 분류 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b7e3552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] score: 0.92\n",
      "[2] score: 0.90\n",
      "[3] score: 0.92\n",
      "[4] score: 0.92\n",
      "[5] score: 0.94\n",
      "[6] score: 0.92\n",
      "[7] score: 0.94\n",
      "[8] score: 0.94\n",
      "[9] score: 0.96\n",
      "[10] score: 0.94\n",
      "[11] score: 0.96\n",
      "[12] score: 0.96\n",
      "[13] score: 0.96\n",
      "[14] score: 0.96\n",
      "[15] score: 0.96\n",
      "[16] score: 0.96\n",
      "[17] score: 0.96\n",
      "[18] score: 0.95\n",
      "[19] score: 0.96\n",
      "[20] score: 0.95\n",
      "[21] score: 0.95\n",
      "[22] score: 0.95\n",
      "[23] score: 0.95\n",
      "[24] score: 0.95\n",
      "[25] score: 0.96\n",
      "[26] score: 0.94\n",
      "[27] score: 0.95\n",
      "[28] score: 0.95\n",
      "[29] score: 0.94\n",
      "[30] score: 0.94\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#1 . 데이터 로드\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y= cancer.target\n",
    "\n",
    "#2. 데이터 확인  \n",
    "#print(\"데이터 수 = %d 특징량 = %d\" % (X.shape[0], X.shape[1])) #(150,4) \n",
    "pd.DataFrame(X, columns=cancer.feature_names).head()\n",
    "\n",
    "# 데이터 표시(목적 변수)\n",
    "#print(\"데이터 수 = %d\" % (y.shape[0]))\n",
    "#print(y)\n",
    "\n",
    "#3. 데이터 분할\n",
    "X_train, X_test, y_train,y_test  = train_test_split(X,y, random_state = 0) \n",
    "#4.분류 모형 \n",
    "list_nn =[]\n",
    "list_score =[]\n",
    "for k in range(1,31) : # 1~30 \n",
    "    model = KNeighborsClassifier(n_neighbors =  k)\n",
    "    model.fit(X_train, y_train)  # 학습 데이터로  모델 실행     \n",
    "    y_pred  = model.predict(X_test)  # 테스트 데이터로 예측    \n",
    "    score  = model.score(X_test, y_test) # 테스트 데이터로 평가 -> R2값이 1이면 완벽예측 , 0이면 평균\n",
    "                                         # 분류 -> score  -> accuracy_score랑 같다.  \n",
    "    print(\"[%d] score: {:.2f}\".format(score) % k)\n",
    "    \n",
    "    list_nn.append(k)\n",
    "    list_score.append(score)\n",
    "    \n",
    "#5. 시각화      \n",
    "plt.ylim(0.9,1.0)   ; \n",
    "plt.xlabel('n_neighbors');\n",
    "plt.ylabel('score');\n",
    "plt.plot(list_nn, list_score);\n",
    "#[평가 ]  k =1~30 /  k=9,  96% 정확도 \n",
    "# * k값은  적은 수치도 문제가 없다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19269452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns=cancer.feature_names).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceb8239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 수 = 569\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터 수 = %d\" % (y.shape[0]))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa425ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
