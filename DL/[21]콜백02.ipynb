{
 "cells": [
  {
   "cell_type": "raw",
   "id": "16b1a786",
   "metadata": {
    "id": "d31af14f"
   },
   "source": [
    "<<콜백 함수를 이용해서 각 에폭이 종료되면 모델을 저장하는 함수를 작성 >>\n",
    "tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor: str = 'val_loss',\n",
    "    verbose: int = 0,\n",
    "    save_best_only: bool = False, # True 최고값, #False일 경우 에폭마다 모델을 저장\n",
    "    save_weights_only: bool = False,\n",
    "    mode: str = 'auto',\n",
    "    save_freq='epoch', #정수를 입력하면 해당 정수 만큼의 배치만큼 저장\n",
    "    options=None, #tf.train.checkpointOptions의 인스턴스가 매핑\n",
    "    initial_value_threshold=None, #save_best_only = True일때 사용,모니터지표 사용\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    " filepath = os.path.join(working_dir, 'ckpt', file_name). filepath \n",
    " weights.{epoch:02d}-{val_loss:.2f}.hdf5\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7820c0",
   "metadata": {},
   "source": [
    "<img src='etc/콜백함수.png' width=1000 height= 600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fcd7c50",
   "metadata": {
    "id": "6fcd7c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "#1.OS환경만들기  \n",
    "import os  # 탐색기 모듈. os.path\n",
    "os.environ['KERAS_BACKEND']  ='tensorflow'\n",
    "kerasBKED  = os.environ['KERAS_BACKEND']\n",
    "print(kerasBKED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e19e15",
   "metadata": {
    "id": "96e19e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.모듈 추가.  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, InputLayer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68dd78e2",
   "metadata": {
    "id": "68dd78e2"
   },
   "outputs": [],
   "source": [
    "#3.작업 디렉토리 생성\n",
    "saveDir='./cifar10/'\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.makedirs(saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9a4729",
   "metadata": {
    "id": "6a9a4729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#4. 데이터 로드  \n",
    "batch_size  = 32\n",
    "num_classes =10\n",
    "epochs  =10 \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train.shape[0])\n",
    "print(x_test.shape[0])\n",
    "\n",
    "y_train  =tf. keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test  = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train =x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8b987c",
   "metadata": {
    "id": "1d8b987c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5 모형만들기  , 모델 만들기  \n",
    "model  = Sequential() \n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05cde55c",
   "metadata": {
    "id": "05cde55c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6. 컴파일 \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bf51933",
   "metadata": {},
   "source": [
    "filepath = os.path.join(working_dir, 'ckpt', file_name). filepath \n",
    " weights.{epoch:02d}-{val_loss:.2f}.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9327c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. 콜백함수 \n",
    "es_cb = EarlyStopping(monitor='val_loss' , patience =2, verbose =1, mode='auto')\n",
    "\n",
    "file_path= os.path.join(saveDir,'Cifar10_convert.{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5' )\n",
    "cp_cb = ModelCheckpoint(filepath =file_path , monitor ='val_loss',verbose=1, save_best_only =True, mode ='auto' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a98a99e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.4354 - accuracy: 0.4768\n",
      "Epoch 1: val_loss improved from inf to 169.70554, saving model to ./cifar10\\Cifar10_convert.01-1.44-169.71.hdf5\n",
      "1563/1563 [==============================] - 60s 36ms/step - loss: 1.4354 - accuracy: 0.4768 - val_loss: 169.7055 - val_accuracy: 0.3931\n",
      "Epoch 2/10\n",
      "   3/1563 [..............................] - ETA: 45s - loss: 1.2128 - accuracy: 0.5729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561/1563 [============================>.] - ETA: 0s - loss: 1.0293 - accuracy: 0.6362\n",
      "Epoch 2: val_loss did not improve from 169.70554\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.0293 - accuracy: 0.6361 - val_loss: 244.9412 - val_accuracy: 0.3570\n",
      "Epoch 3/10\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.8762 - accuracy: 0.6924\n",
      "Epoch 3: val_loss improved from 169.70554 to 135.83369, saving model to ./cifar10\\Cifar10_convert.03-0.88-135.83.hdf5\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8763 - accuracy: 0.6924 - val_loss: 135.8337 - val_accuracy: 0.4930\n",
      "Epoch 4/10\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7759 - accuracy: 0.7261\n",
      "Epoch 4: val_loss improved from 135.83369 to 99.96165, saving model to ./cifar10\\Cifar10_convert.04-0.78-99.96.hdf5\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 0.7759 - accuracy: 0.7261 - val_loss: 99.9616 - val_accuracy: 0.5746\n",
      "Epoch 5/10\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.7098 - accuracy: 0.7495\n",
      "Epoch 5: val_loss did not improve from 99.96165\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.7097 - accuracy: 0.7496 - val_loss: 227.2559 - val_accuracy: 0.4352\n",
      "Epoch 6/10\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6473 - accuracy: 0.7748\n",
      "Epoch 6: val_loss did not improve from 99.96165\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6471 - accuracy: 0.7748 - val_loss: 176.5986 - val_accuracy: 0.5020\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "#8. 학습실행  \n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs= epochs , \n",
    "                    validation_data =  (x_test, y_test),\n",
    "                    callbacks =[es_cb ,  cp_cb] , \n",
    "                    shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270f09f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "#!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f7d48a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_weights', 'optimizer_weights']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File('./cifar10/Cifar10_convert.04-0.78-99.96.hdf5', 'r')\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b833976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_weights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>optimizer_weights</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "0      model_weights\n",
       "1  optimizer_weights"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df =pd.DataFrame(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274788b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./cifar10/Cifar10_convert.04-0.78-99.96.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31ed129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1180160   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1250858 (4.77 MB)\n",
      "Trainable params: 1250858 (4.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5e3104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d shape (3, 3, 3, 32)\n",
      "conv2d min -0.29388654232025146\n",
      "conv2d max 0.25933653116226196\n",
      " 1 : conv2d bias shape (32,)\n",
      " 1 : conv2d bias min -0.1412496268749237\n",
      " 1 : conv2d bias max 0.09859113395214081\n",
      " 1 : conv2d bias mean -0.0016726329922676086\n",
      "conv2d_1 shape (3, 3, 32, 32)\n",
      "conv2d_1 min -0.4659684896469116\n",
      "conv2d_1 max 0.34798142313957214\n",
      " 1 : conv2d_1 bias shape (32,)\n",
      " 1 : conv2d_1 bias min -0.05662478134036064\n",
      " 1 : conv2d_1 bias max 0.06535575538873672\n",
      " 1 : conv2d_1 bias mean -0.007831165567040443\n",
      "conv2d_2 shape (3, 3, 32, 64)\n",
      "conv2d_2 min -0.627456545829773\n",
      "conv2d_2 max 0.36283427476882935\n",
      " 1 : conv2d_2 bias shape (64,)\n",
      " 1 : conv2d_2 bias min -0.13494592905044556\n",
      " 1 : conv2d_2 bias max 0.16048304736614227\n",
      " 1 : conv2d_2 bias mean 0.00380896870046854\n",
      "conv2d_3 shape (3, 3, 64, 64)\n",
      "conv2d_3 min -0.5458937287330627\n",
      "conv2d_3 max 0.37517398595809937\n",
      " 1 : conv2d_3 bias shape (64,)\n",
      " 1 : conv2d_3 bias min -0.07902579754590988\n",
      " 1 : conv2d_3 bias max 0.15205074846744537\n",
      " 1 : conv2d_3 bias mean 0.019434815272688866\n",
      "dense shape (2304, 512)\n",
      "dense min -0.5058982372283936\n",
      "dense max 0.4362587630748749\n",
      " 1 : dense bias shape (512,)\n",
      " 1 : dense bias min -0.11001325398683548\n",
      " 1 : dense bias max 0.14733166992664337\n",
      " 1 : dense bias mean -0.005323552060872316\n",
      "dense_1 shape (512, 10)\n",
      "dense_1 min -0.4548255205154419\n",
      "dense_1 max 0.3416922092437744\n",
      " 1 : dense_1 bias shape (10,)\n",
      " 1 : dense_1 bias min -0.15584702789783478\n",
      " 1 : dense_1 bias max 0.11778077483177185\n",
      " 1 : dense_1 bias mean -0.0036596376448869705\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "        weights = layer.get_weights()\n",
    "        if weights:\n",
    "            print(f'{layer.name} shape {weights[0].shape}')\n",
    "            print(f'{layer.name} min {weights[0].min()}')\n",
    "            print(f'{layer.name} max {weights[0].max()}')\n",
    "            \n",
    "            if len(weights) > 1:\n",
    "                print(f' 1 : {layer.name} bias shape {weights[1].shape}')\n",
    "                print(f' 1 : {layer.name} bias min {weights[1].min()}')\n",
    "                print(f' 1 : {layer.name} bias max {weights[1].max()}')\n",
    "                print(f' 1 : {layer.name} bias mean {weights[1].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d0dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "281e6864",
   "metadata": {},
   "source": [
    "model.compile(loss=..., optimizer=...,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 10\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen\n",
    "# so far.\n",
    "model.fit(epochs=EPOCHS, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the\n",
    "# model.\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4aee4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 0.6999 - accuracy: 0.7547\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.6479 - accuracy: 0.7717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24dffb2edd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
    "# Then run the tensorboard command to view the visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8929fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
