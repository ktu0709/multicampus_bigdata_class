{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0fc3c38",
   "metadata": {},
   "source": [
    "### 단층, 다층 퍼셉트론  모델 설계 후  결과 확인  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba6dfa1b",
   "metadata": {},
   "source": [
    "1) 게이트 연산을 해보자. \n",
    "    - 퍼셉트론 정리  _ 단층 퍼셉트론   \n",
    "    - model.add(Dense(1, input_shape=(2,), activation ='linear')) \n",
    " \n",
    "2) 내적연산이 이루어지는 다층 퍼셉트론을 구현해보자.  ( 연산의 비용이 크고, 벡터화를 이용해서 연산  )  \n",
    "      - 내적 연산확인  : tf.matmul() \n",
    "      - 다층 퍼셉트론\n",
    "      <ex> 특징 데이터 2개  출력 3개로 하겠다.  \n",
    "       model.add(Dense(10, input_shape=(2,), activation ='..'))\n",
    "       model.add(Dense(3,  activation ='. ')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287b3a3",
   "metadata": {},
   "source": [
    "### Q1). 단층 퍼셉트론 적용 알고리즘의 프로세스를 구현  \n",
    "\n",
    "- 1) 순차모형  :  tf.keras.models.Sequential\n",
    "- 2) 레이어 구성  :tf.keras.layers.Dense  \n",
    "- 3) f(net)   :  tf.keras.layers.Dense( units,  activation='linear'  )  \n",
    "- 4) 최적화 함수 : tf.keras.optimizers.experimental.SGD()   \n",
    "- 5) 손실함수  : tf.keras.losses.mse \n",
    "- 6) 평가지표  : 정답률  acc\n",
    "\n",
    "<< 모델 구성  -> 레이어 추가  -> 컴파일  -> 학습  >>  \n",
    "\n",
    "###  fit(   x=None,    y=None,    batch_size=None,    epochs=1 )  \n",
    "\n",
    "ex) 1000개 샘플  / 배치 100  =  10개의 배치로 나누어 처리된다.   ->  하나의 에폭에서 최적화 함수는 10번 실행된다. \n",
    "\n",
    "-----> 에폭  10  = 최적화 함수  10  *(배치당 최적화 실행 회수)  \n",
    "\n",
    "10*10  =100번  최적화 함수가 실행된다.   \n",
    "\n",
    "-----------ex)  샘플50 , 에폭이 5, 배치 1   = 최적화 함수 실행은 ?   50* 5/ 1   = 250 번 \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd362f16",
   "metadata": {},
   "source": [
    "문제 :  전체 데이터셋이 200개 샘플 / 에폭수 10 / 배치크기 5 \n",
    "\n",
    "1) 하나의 에폭에서 최적화 함수는 몇번 실행되나 ?     [ 총샘플수  / 배치 크기]  40번실행 \n",
    "\n",
    "2) 전체 학습과정에서 최적화 함수는 총 몇번 실행되나?   [하나의 에폭최적화함수 실행횟수 * 에폭수  ]   400번실행 \n",
    "\n",
    "*최적화함수는 모델학습시 가중치 업데이트 목적을 가지고 실행하는 횟수가 에폭수, 데이터셋크기, 배치크기로 결정된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f01ae983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q1-1 )모듈 임포트  \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import  Sequential\n",
    "from tensorflow.keras.layers  import  Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses  import mse\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782432e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3242 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2771 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2326 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1906 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1509 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1134 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0779 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0444 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0127 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9827 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9543 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9273 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9018 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8776 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8546 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8328 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8121 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7924 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7737 - Accuracy: 0.5000 - precision: 1.0000 - recall: 0.3333\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7559 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7389 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7227 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7073 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6927 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6786 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6652 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6524 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6402 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6285 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6173 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6065 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5962 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5863 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5768 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5676 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5588 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5503 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5422 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5343 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5267 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5194 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5123 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5054 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4988 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4924 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4861 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4801 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4742 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4685 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4630 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4576 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4524 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4473 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4423 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4374 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4327 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4281 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4236 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4192 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4149 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4107 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4065 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4025 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3985 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3946 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3908 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3871 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3834 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3798 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3763 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3728 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3694 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3661 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3628 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3595 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3563 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3532 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3501 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3470 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3440 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3410 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3381 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3352 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3324 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3296 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3268 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3241 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3214 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3187 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3161 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3135 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3110 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3084 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3059 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3035 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3010 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2986 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2962 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2939 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2916 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2893 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2870 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2848 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2825 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2803 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2782 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2760 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2739 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2718 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2697 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2677 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2656 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2636 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2616 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2597 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2577 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2558 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2539 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2520 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2501 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2483 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2464 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2446 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2428 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2411 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2393 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2376 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2359 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2342 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2325 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2308 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2292 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2275 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2259 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2243 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2227 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2212 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2196 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2181 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2165 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2150 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2135 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2121 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2106 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2092 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2077 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2063 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2049 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2035 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2021 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2008 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1994 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1981 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1968 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1955 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1942 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1929 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1916 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1903 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1891 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1879 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1866 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1854 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1842 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1831 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1819 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1807 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1796 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1784 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1773 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1762 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1751 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1740 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1729 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1718 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1708 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1697 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1687 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1676 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1666 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1656 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1646 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1636 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1626 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1616 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1607 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1597 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1588 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1578 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1569 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1560 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1551 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1542 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1533 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1524 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1516 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1507 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1498 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1490 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1481 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "가중치  : [array([[ 0.7870234 ],\n",
      "       [-0.00540723]], dtype=float32), array([0.37822664], dtype=float32)]\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.1473 - Accuracy: 0.7500 - precision: 1.0000 - recall: 0.6667\n",
      "evaluate[0.147317036986351, 0.75, 1.0, 0.6666666865348816]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "예측값 [0.37822664]  - 정답  [0]\n",
      "예측값 [1.1652501]  - 정답  [1]\n",
      "예측값 [0.37281942]  - 정답  [1]\n",
      "예측값 [1.1598428]  - 정답  [1]\n"
     ]
    }
   ],
   "source": [
    "#Q1-2) 데이터 준비  -> OR 연산자로 모델을 확인 해보자.  \n",
    "data  =  np.array([ [0,0] , [1,0] ,[0,1] ,[1,1] ]   )   # X1, X2  의  2개의 특성을 가진 데이터가 4개이다.  \n",
    "label =  np.array( [[0],[1],[1],[1] ] )  #정답 라벨 y    1*4 \n",
    "\n",
    "# 1-3  모델 생성 \n",
    "model =  Sequential()\n",
    "\n",
    "#1-4 모델에 히든 레이어를 추가하겠다. -> 두개의 특성을 가진 1차원 데이터를 입력 받고 한개의 출력을 가진  Dense층  \n",
    "#Dense(1,) -> 하나의 히든 레이어를 만들겠다. \n",
    "#은닉계층이 1개이고 입력 계층 단위계수가 2개인것을 [ 퍼셉트론] 이라고 한다. \n",
    "model.add(Dense(1,input_shape=(2,) , activation='linear' )) # 단층 퍼셉트론  -> 퍼셉트론을 생성  \n",
    "\n",
    "#1-5  모델준비   -> 경사하강법 개선에 대한 속성, 로스, 정답률  등 평가 지표[정확도, 정밀도, 재현율, F1] 회귀 = 평균절대오차MAE, MSE \n",
    "model.compile(optimizer = SGD(), loss = mse, metrics = ['Accuracy','Precision' , 'Recall']) \n",
    "\n",
    "#1-6 학습  fit() \n",
    "model.fit(data,label,epochs= 200)  \n",
    "     \n",
    "#1-7 평가지표 및 가중치 값 확인 등 정보확인\n",
    "print(f'가중치  : {model.get_weights()}') # 모델 가중치 확인 ->  파일저장 [학습결과 /모델 재사용 공유 / 에폭별로 시간간격 /앙상블 ]\n",
    "print(f'evaluate{model.evaluate(data,label)}' )\n",
    "\n",
    "#1-8 예측 \n",
    "preds  = model.predict(data)\n",
    "for a,b   in zip (preds, label):\n",
    "    print(f'예측값 {a}  - 정답  {b}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64147bf",
   "metadata": {},
   "source": [
    "Q2) 단층 퍼셉트론을 이용한 AND 연산자 학습을 해보자.\n",
    "1. 데이터 준비:  입력 데이터는 [ [0,0], [0,1], [1,0], [1,1] ], 정답레이블 [ [0], [0], [0], [1] ]  \n",
    "\n",
    "2.  모델 구성: tf.keras.models.Sequential을 사용하여 순차 모델 구성\n",
    "\n",
    "3.  레이어 구성: tf.keras.layers.Dense를 사용하여 단일 레이어를 구성 \n",
    "    두 개의 입력을 받고 하나의 출력, units=1과 activation='linear' 파라미터를 사용\n",
    "   \n",
    "4. 최적화 함수: tf.keras.optimizers.experimental.SGD를 사용\n",
    "5. 손실 함수: tf.keras.losses.mse \n",
    "6. 평가 지표:  metrics=['accuracy']를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0230e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "예측값 [-0.04419534]  - 정답  [0]\n",
      "예측값 [0.95047355]  - 정답  [0]\n",
      "예측값 [-0.3896703]  - 정답  [0]\n",
      "예측값 [0.6049986]  - 정답  [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(12,5))\\n\\nplt.subplot(1,2,1)\\nplt.plot(history.history['loss'],label='Training Loss')\\nplt.plot(history.history['val_loss'],label='val_loss')\\nplt.legend()\\nplt.title('loss')\\n\\nplt.subplot(1,2,2)\\nplt.plot(history.history['accuracy'],label='Training accuracy')\\nplt.plot(history.history['val_accuracy'],label='val_accuracy')\\nplt.legend()\\nplt.title('accuracy')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data  =  np.array([ [0,0] , [0,1] ,[1,0] ,[1,1] ]   )\n",
    "label =  np.array( [[0],[0],[0],[1] ] )  \n",
    "\n",
    "model =  Sequential()\n",
    "model.add(Dense(1,input_shape=(2,) , activation='linear' ))\n",
    "model.compile(optimizer = SGD(), loss = mse, metrics = ['accuracy']) \n",
    "\n",
    "history = model.fit(data,label,epochs= 100,verbose=0)  \n",
    "\n",
    "\n",
    "#1-8 예측 \n",
    "preds  = model.predict(data)\n",
    "for a,b   in zip (preds, label):\n",
    "    print(f'예측값 {a}  - 정답  {b}') \n",
    "\n",
    "'''\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'],label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.legend()\n",
    "plt.title('loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'],label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.title('accuracy')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f2404",
   "metadata": {},
   "source": [
    "Q3)  XOR로 다층 퍼셉트론 구현을 해보자.  \n",
    "\n",
    "1. 데이터 준비: 입력 데이터는 [ [0,0], [0,1], [1,0], [1,1] ]이며, 정답 레이블 [ [0], [1], [1], [0] ]\n",
    "\n",
    "2. 모델 구성: 순차 모델은 tf.keras.models.Sequential을 사용하여 구성\n",
    "\n",
    "3. 레이어 구성: 순차 모델 사용 (tf.keras.models.Sequential) \n",
    "    - 첫 번째 은닉층: units=2 (두 개의 노드)와 activation='relu'\n",
    "    - 출력층: units=1 (하나의 노드)와 activation='sigmoid'\n",
    "\n",
    "4. 최적화 함수: tf.keras.optimizers.Adam\n",
    "\n",
    "5. 손실 함수: tf.keras.losses.BinaryCrossentropy\n",
    "\n",
    "6. 평가 지표:  metrics=['accuracy']를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aeec204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.7030 - accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7025 - accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7014 - accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7009 - accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7004 - accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6999 - accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6994 - accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6989 - accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6979 - accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6970 - accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6965 - accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6960 - accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6946 - accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6914 - accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6901 - accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6888 - accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6880 - accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6871 - accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6867 - accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6859 - accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6855 - accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6834 - accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6826 - accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6822 - accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6814 - accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6810 - accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6806 - accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6798 - accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6775 - accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6771 - accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6763 - accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6755 - accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6748 - accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6744 - accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6740 - accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6736 - accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6732 - accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6725 - accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6713 - accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6706 - accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6698 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6694 - accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6690 - accuracy: 0.5000\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6687 - accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6683 - accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6679 - accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6676 - accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6672 - accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6668 - accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6664 - accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6657 - accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6650 - accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6642 - accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6635 - accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6628 - accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6624 - accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6614 - accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6606 - accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6603 - accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6592 - accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6585 - accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.5000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6571 - accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.5000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.5000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6561 - accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6554 - accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6544 - accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6540 - accuracy: 0.5000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6537 - accuracy: 0.5000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.5000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.5000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.5000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.5000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.5000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6513 - accuracy: 0.5000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.5000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6507 - accuracy: 0.5000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.5000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.5000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.5000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.5000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.5000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.5000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.5000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.5000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6465 - accuracy: 0.5000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6461 - accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6455 - accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6452 - accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6446 - accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6433 - accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6414 - accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.7500\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6402 - accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.7500\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6363 - accuracy: 0.7500\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6343 - accuracy: 0.7500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6331 - accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.7500\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.7500\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.7500\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6322 - accuracy: 0.7500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6320 - accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.7500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6315 - accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6309 - accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6308 - accuracy: 0.7500\n",
      "loss : 0.6307762861251831 , Accuracy : 0.75\n"
     ]
    }
   ],
   "source": [
    "data  =  np.array([ [0,0] , [0,1] ,[1,0] ,[1,1] ]   )\n",
    "label =  np.array( [[0],[1],[1],[0] ] )  \n",
    "\n",
    "model =  Sequential()\n",
    "model.add(Dense(2,input_shape=(2,) , activation='relu' ))\n",
    "model.add(Dense(1, activation='sigmoid' ))\n",
    "model.compile(optimizer = 'Adam', loss = 'BinaryCrossentropy', metrics = ['accuracy']) \n",
    "\n",
    "history = model.fit(data,label,epochs= 200)  \n",
    "\n",
    "loss , accuracy = model.evaluate(data,label)\n",
    "print(f'loss : {loss} , Accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccc5dbde",
   "metadata": {},
   "source": [
    "Q3) 최소 구현 모델을 작성해보자. 임의의 숫자를 입력하면 짝수 ,홀수 인지 판정하는 모델을 만들자\n",
    "0~5 난수 20개 , 짝수 [0,1] , 홀수[1,0]로 입력해서 각 예측한 확률값을 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4cb7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = np.random.randint(0,5,(20,1))\n",
    "label = np.where(data %2 == 0, [0,1] , [1,0])\n",
    "\n",
    "\n",
    "model =  Sequential([\n",
    "                    tf.keras.layers.Dense(units=512,activation='relu',input_shape=(1,)),\n",
    "                    tf.keras.layers.Dense(units=256,activation='relu'),\n",
    "                    tf.keras.layers.Dense(units=2,activation='softmax'),\n",
    "                    ])\n",
    "\n",
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "history = model.fit(data,label,epochs= 700,batch_size=8,verbose=0,validation_split=0.2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1759b88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측\n",
    "model.predict([1])\n",
    "#model.predict([3,4])\n",
    "keras.utils.plot_model(model,show_shapes=True, to_file='img/my_model.png',show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97456db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6abdac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
