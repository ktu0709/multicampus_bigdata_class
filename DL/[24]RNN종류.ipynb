{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d1fa93f",
   "metadata": {},
   "source": [
    "### * RNN 주요 레이어 종류\n",
    "#### (1) SimpleRNN :가장 간단한 형태의 RNN레이어, 활성화 함수로 tanh가 사용됨(tanh: -1 ~ 1 사이의 값을 반환)\n",
    "#### (2) LSTM(Long short Term Memory) : 입력 데이터와 출력 사이의 거리가 멀어질수로 연관 관계가 적어진다(Long Term Dependency,장기의존성 문제), LSTM은 장기 의존성 문제를 해결하기 위해 출력값외에 셀상태(cell state)값을 출력함, 활성화 함수로 tanh외에 sigmoid가 사용됨\n",
    "#### (3) GRU(Gated Recurent Unit) : 뉴욕대 조경현 교수 등이 제안, LSTM보다 구조가 간단하고 성능이 우수함\n",
    "\n",
    "<<참고 : https://colah.github.io/posts/2015-08-Understanding-LSTMs/>>\n",
    "https://link.springer.com/article/10.1007/s11063-009-9096-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c704b25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84aadeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4, 1) (6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 4, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.]],\n",
       "\n",
       "       [[3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.]],\n",
       "\n",
       "       [[4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.]],\n",
       "\n",
       "       [[5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.]]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence data\n",
    "X = np.array([[0,1,2,3],\n",
    "              [1,2,3,4],\n",
    "              [2,3,4,5],\n",
    "              [3,4,5,6],\n",
    "              [4,5,6,7],\n",
    "              [5,6,7,8]],dtype=np.float32)\n",
    "\n",
    "x_data = tf.reshape(X,(-1,4,1))  # (6,4,1)\n",
    "\n",
    "y_data = np.array([4,5,6,7,8,9],dtype=np.float32)\n",
    "\n",
    "print(x_data.shape,y_data.shape)\n",
    "# print(type(x_data),type(y_data))\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54cc4c",
   "metadata": {},
   "source": [
    "### [1] SimpleRNN\n",
    "#### 가장 간단한 형태의 RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af74b368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\rnn\\simple_rnn.py:130: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 4, 300)            90600     \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 300)               180300    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271201 (1.03 MB)\n",
      "Trainable params: 271201 (1.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Q1)  SimpleRNN모델 구현하자.  \n",
    "#X :  (6,4,1) \n",
    "# Wx : (1,300 )   , : 입력가중치(입력차원 , 뉴런) =파라미터 개수 = 1*300 = 300\n",
    "# Wh (300,300) , : 숨겨진 상태 가중치 : (300,300) = (유닛 개수,숨겨진 상태) , 파라미터 = 300 * 300 = 90,000\n",
    "# b (300) , param 90600       = wx+ wh + b  = 90,600\n",
    "#, OUt (None, 4, 300)  \n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=300,return_sequences=True,input_shape=[4,1]),\n",
    "    \n",
    "#X :  (None, 4, 300)   \n",
    "# Wx : (300,300 )   , 300 * 300 = 90000\n",
    "#Wh (300,300) ,       300 * 300 - 90000\n",
    "#    b (300) ,        90000 + 90000 + 300 = 180300    \n",
    "#    param 180300   \n",
    "#    , OUt (None,300)  \n",
    "    tf.keras.layers.SimpleRNN(units=300),\n",
    "    tf.keras.layers.Dense(1)     #출력차원이 1, 가중치 형태 = (300,1) = 300 + 1 = 301\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87af6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\taeeon.kim\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 4s 4s/step - loss: 35.6214\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5345\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.2700\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.1489\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4105\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2029\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9213\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2904\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9717\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8597\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7301\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0862\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2957\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1317\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7463\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4856\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5922\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8589\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8493\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5784\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3858\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4157\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5376\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5734\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4707\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3213\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2651\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3331\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3813\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2975\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1781\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1512\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1942\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2039\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1427\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0765\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0818\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1230\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1055\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0498\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0410\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0700\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0695\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0341\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0219\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0457\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0472\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0209\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0197\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0377\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0341\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0177\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0227\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0341\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0246\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0168\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0251\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0266\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0170\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0168\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0226\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0182\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0133\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0170\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0176\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0125\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0125\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0150\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0121\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0098\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0117\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0112\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0087\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0093\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0101\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0083\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0080\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0090\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0081\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0072\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0079\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0076\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0066\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0069\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0069\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0061\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0061\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0063\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0055\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0056\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0050\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0046\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0044\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0045\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0042\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 895ms/step\n",
      "[[4.0117373]\n",
      " [4.957607 ]\n",
      " [5.956311 ]\n",
      " [7.057538 ]\n",
      " [8.069312 ]\n",
      " [8.893594 ]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_data,y_data,epochs=100,verbose=1)\n",
    "print(model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3eb0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "[[9.513967]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[1.1378653]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([[[6.],[7.],[8.],[9.]]])))\n",
    "print(model.predict(np.array([[[-1.],[0.],[1.],[2.]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b9e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 575ms/step - loss: 0.0039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0038801219779998064"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_data,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e50856",
   "metadata": {},
   "source": [
    "### [2] LSTM(Long short Term Memory)\n",
    "#### 입력 데이터와 출력 사이의 거리가 멀어질수로 연관 관계가 적어진다(Long Term Dependency,장기의존성 문제)\n",
    "#### LSTM은 장기 의존성 문제를 해결하기 위해 출력값외에 셀상태(cell state)값을 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a87479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 4, 300)            362400    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 300)               721200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1083901 (4.13 MB)\n",
      "Trainable params: 1083901 (4.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Q2) RNN 순환 신경망 구현  : LSTM\n",
    "model = tf.keras.Sequential([   \n",
    " #X :  (6,4,1) \n",
    "# Wx : (1,4*300 )   , Wh (300,4*300) , b (4*300) , param  4*90600      , OUt (None, 4, 300)\n",
    "    tf.keras.layers.LSTM(units=300,return_sequences=True,input_shape=[4,1]),  \n",
    "    \n",
    "  #X :  None, 4, 300\n",
    "# Wx : (300,4*300 )   , Wh (300,4*300) , b (4*300) , param  4*180300     , OUt   (None, 300) \n",
    "    tf.keras.layers.LSTM(units=300),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bed28ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 45.4470\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 39.9041\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 34.3499\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 28.2107\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 21.2174\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 13.5783\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.3604\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.7415\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1865\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.5998\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.9333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.9104\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.8821\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.9918\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8116\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4072\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5584\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9746\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4211\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7558\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9168\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.8978\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7265\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4490\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1207\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7981\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5319\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3593\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2971\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3367\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4459\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5773\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6830\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7302\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7095\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6340\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5311\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4305\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3551\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3159\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3119\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3336\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3673\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3994\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4198\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4230\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4089\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3814\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3473\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3141\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2882\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2734\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2699\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2750\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2836\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2904\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2914\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2853\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2734\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2588\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2450\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2348\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2295\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2286\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2302\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2321\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2325\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2302\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2254\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2190\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2124\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2068\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2031\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2013\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2007\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2003\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1993\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1971\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1939\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1902\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1865\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1836\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1814\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1800\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1788\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1774\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1756\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1732\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1706\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1680\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1656\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1636\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1618\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1603\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1586\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1567\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1547\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1525\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1504\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1485\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[3.3906348]\n",
      " [5.1253448]\n",
      " [6.3947206]\n",
      " [7.3170376]\n",
      " [7.9993153]\n",
      " [8.5134535]]\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 예측\n",
    "model.fit(x_data,y_data,epochs=100,verbose=1)\n",
    "print(model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59994a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[8.907026]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[1.2317121]]\n"
     ]
    }
   ],
   "source": [
    "# 학습되지 않은 입력 데이터에 대한 예측 결과\n",
    "print(model.predict(np.array([[[6.],[7.],[8.],[9.]]])))\n",
    "print(model.predict(np.array([[[-1.],[0.],[1.],[2.]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3c1e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.1467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14668039977550507"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_data,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd12f4",
   "metadata": {},
   "source": [
    "### [3] GRU(Gated Recurent Unit)\n",
    "#### 뉴욕대 조경현 교수 등이 제안, LSTM보다 구조가 간단하고 성능이 우수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09235443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 4, 300)            272700    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 300)               541800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814801 (3.11 MB)\n",
      "Trainable params: 814801 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 순환 신경망 구현  : GRU\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(units=300,return_sequences=True,input_shape=[4,1]),\n",
    "    tf.keras.layers.GRU(units=300),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861c8e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 43.3607\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 26.6226\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 13.3136\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9350\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5827\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.0200\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7868\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.9054\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.4495\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3455\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3510\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3494\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8749\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4750\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8677\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.9555\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.7666\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3940\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9521\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5479\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2610\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1307\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1504\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2724\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4258\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5421\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5792\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5313\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4232\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2941\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1810\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1076\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0808\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0932\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1291\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1709\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2036\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2181\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2117\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1876\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1531\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1171\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0876\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0700\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0659\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0729\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0860\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0991\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1073\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1079\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1013\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0899\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0775\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0674\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0616\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0607\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0634\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0678\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0719\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0741\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0737\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0709\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0668\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0625\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0592\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0575\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0575\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0586\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0601\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0612\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0614\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0606\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0590\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0573\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0558\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0549\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0546\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0549\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0553\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0555\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0554\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0550\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0542\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0534\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0527\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0522\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0520\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0519\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0519\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0518\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0516\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0512\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0507\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0503\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0499\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0496\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0494\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0492\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0490\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0488\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[3.646335 ]\n",
      " [5.0229125]\n",
      " [6.2036786]\n",
      " [7.1978498]\n",
      " [8.025341 ]\n",
      " [8.709657 ]]\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 예측\n",
    "model.fit(x_data,y_data,epochs=100,verbose=1)\n",
    "print(model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bd5196a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[9.273868]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[2.0855718]]\n"
     ]
    }
   ],
   "source": [
    "# 학습되지 않은 입력 데이터에 대한 예측 결과\n",
    "print(model.predict(np.array([[[6.],[7.],[8.],[9.]]])))\n",
    "print(model.predict(np.array([[[-1.],[0.],[1.],[2.]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdc5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
